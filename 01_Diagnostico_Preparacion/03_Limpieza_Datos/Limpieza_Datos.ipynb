{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza CEPRE UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omarc\\AppData\\Local\\Temp\\ipykernel_25596\\553627686.py:52: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('IDHASH').apply(lambda group: group.ffill())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del Análisis Preliminar\n",
      "Número de registros antes de limpieza: 33809\n",
      "Número de registros después de limpieza: 33809\n",
      "Duplicados eliminados: 0\n",
      "Valores nulos cambiados a 'Sin Datos': 0\n",
      "\n",
      "Valores distintos por columna:\n",
      "IDHASH: 19661 valores únicos\n",
      "COLEGIO: 13499 valores únicos\n",
      "COLEGIO_DEPA: 25 valores únicos\n",
      "COLEGIO_PROV: 167 valores únicos\n",
      "COLEGIO_DIST: 572 valores únicos\n",
      "COLEGIO_PAIS: 1 valores únicos\n",
      "COLEGIO_ANIO_EGRESO: 29 valores únicos\n",
      "ESPECIALIDAD: 31 valores únicos\n",
      "ANIO_POSTULA: 8 valores únicos\n",
      "CICLO_POSTULA: 2 valores únicos\n",
      "DOMICILIO_DEPA: 25 valores únicos\n",
      "DOMICILIO_PROV: 128 valores únicos\n",
      "DOMICILIO_DIST: 340 valores únicos\n",
      "ANIO_NACIMIENTO: 34 valores únicos\n",
      "NACIMIENTO_PAIS: 18 valores únicos\n",
      "NACIMIENTO_DEPA: 26 valores únicos\n",
      "NACIMIENTO_PROV: 179 valores únicos\n",
      "NACIMIENTO_DIST: 800 valores únicos\n",
      "SEXO: 2 valores únicos\n",
      "CALIF_FINAL: 13872 valores únicos\n",
      "INGRESO: 2 valores únicos\n",
      "MODO_INGRESO: 3 valores únicos\n",
      "FECHA_CORTE: 1 valores únicos\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:/Users/omarc/OneDrive/Escritorio/Proyectos VSC/OmarCano/Track Analítico UNI/05_Datos/01_Datos_Crudos/hm_cepre_uni.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "distincts = {col: df[col].unique() for col in df.columns}\n",
    "df = df.apply(lambda col: col.str.strip() if col.dtype == 'object' else col)\n",
    "columns_to_capitalize = ['COLEGIO', 'COLEGIO_DEPA', 'COLEGIO_PROV', 'COLEGIO_DIST', 'COLEGIO_PAIS', 'ESPECIALIDAD',\n",
    "                         'DOMICILIO_DEPA', 'DOMICILIO_PROV', 'DOMICILIO_DIST', 'NACIMIENTO_DEPA', 'NACIMIENTO_PROV',\n",
    "                         'NACIMIENTO_DIST', 'SEXO', 'INGRESO', 'MODO_INGRESO']\n",
    "\n",
    "df[columns_to_capitalize] = df[columns_to_capitalize].apply(lambda col: col.str.title())\n",
    "duplicados = df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "cols_with_nulls = df.columns[df.isnull().any()]\n",
    "df[cols_with_nulls] = df[cols_with_nulls].astype('object')\n",
    "\n",
    "nulos_antes = df.isnull().sum().sum()\n",
    "df.fillna('Sin Datos', inplace=True)\n",
    "nulos_despues = df.isnull().sum().sum()\n",
    "valores_cambiados = nulos_antes - nulos_despues\n",
    "\n",
    "columns_to_impute = ['COLEGIO', 'COLEGIO_DEPA', 'COLEGIO_PROV', 'COLEGIO_DIST', 'COLEGIO_PAIS', 'ESPECIALIDAD',\n",
    "                         'DOMICILIO_DEPA', 'DOMICILIO_PROV', 'DOMICILIO_DIST', 'NACIMIENTO_DEPA', 'NACIMIENTO_PROV',\n",
    "                         'NACIMIENTO_DIST', 'SEXO', 'INGRESO', 'MODO_INGRESO']\n",
    "\n",
    "for column in columns_to_impute:\n",
    "    df[column] = df[column].replace('Sin Datos', pd.NA)\n",
    "\n",
    "df = df.groupby('IDHASH').apply(lambda group: group.ffill())\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "output_path = r'C:/Users/omarc/OneDrive/Escritorio/Proyectos VSC/OmarCano/Track Analítico UNI/05_Datos/02_Datos_Procesados/hm_cepre_uni_limpio.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Resumen del Análisis Preliminar\")\n",
    "print(f\"Número de registros antes de limpieza: {len(df) + duplicados}\")\n",
    "print(f\"Número de registros después de limpieza: {len(df)}\")\n",
    "print(f\"Duplicados eliminados: {duplicados}\")\n",
    "print(f\"Valores nulos cambiados a 'Sin Datos': {valores_cambiados}\")\n",
    "print(\"\\nValores distintos por columna:\")\n",
    "for col, vals in distincts.items():\n",
    "    print(f\"{col}: {len(vals)} valores únicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza ADMISIONES UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omarc\\AppData\\Local\\Temp\\ipykernel_25596\\3168143890.py:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.groupby('IDHASH').apply(lambda group: group.ffill())\n",
      "C:\\Users\\omarc\\AppData\\Local\\Temp\\ipykernel_25596\\3168143890.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('IDHASH').apply(lambda group: group.ffill())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del Análisis Preliminar\n",
      "Número de registros antes de limpieza: 42516\n",
      "Número de registros después de limpieza: 42516\n",
      "Duplicados eliminados: 0\n",
      "Valores nulos cambiados a 'Sin Datos': 24942\n",
      "Valores nulos cambiados a 'Sin Datos' 2: 2516\n",
      "\n",
      "Valores distintos por columna:\n",
      "IDHASH: 26177 valores únicos\n",
      "COLEGIO: 3970 valores únicos\n",
      "COLEGIO_DEPA: 39 valores únicos\n",
      "COLEGIO_PROV: 231 valores únicos\n",
      "COLEGIO_DIST: 819 valores únicos\n",
      "COLEGIO_PAIS: 9 valores únicos\n",
      "COLEGIO_ANIO_EGRESO: 49 valores únicos\n",
      "ESPECIALIDAD: 31 valores únicos\n",
      "ANIO_POSTULA: 4 valores únicos\n",
      "CICLO_POSTULA: 2 valores únicos\n",
      "DOMICILIO_DEPA: 30 valores únicos\n",
      "DOMICILIO_PROV: 208 valores únicos\n",
      "DOMICILIO_DIST: 769 valores únicos\n",
      "ANIO_NACIMIENTO: 49 valores únicos\n",
      "NACIMIENTO_PAIS: 22 valores únicos\n",
      "NACIMIENTO_DEPA: 35 valores únicos\n",
      "NACIMIENTO_PROV: 228 valores únicos\n",
      "NACIMIENTO_DIST: 956 valores únicos\n",
      "SEXO: 2 valores únicos\n",
      "CALIF_FINAL: 11910 valores únicos\n",
      "INGRESO: 2 valores únicos\n",
      "MODALIDAD: 45 valores únicos\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:/Users/omarc/OneDrive/Escritorio/Proyectos VSC/OmarCano/Track Analítico UNI/05_Datos/01_Datos_Crudos/hm_admisiones_uni.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "distincts = {col: df[col].unique() for col in df.columns}\n",
    "df = df.apply(lambda col: col.str.strip() if col.dtype == 'object' else col)\n",
    "columns_to_capitalize = ['COLEGIO', 'COLEGIO_DEPA', 'COLEGIO_PROV', 'COLEGIO_DIST', 'COLEGIO_PAIS', 'ESPECIALIDAD',\n",
    "                         'DOMICILIO_DEPA', 'DOMICILIO_PROV', 'DOMICILIO_DIST', \n",
    "                         'NACIMIENTO_DEPA', 'NACIMIENTO_PROV',\n",
    "                         'NACIMIENTO_DIST', 'SEXO', 'INGRESO', 'MODALIDAD']\n",
    "\n",
    "df[columns_to_capitalize] = df[columns_to_capitalize].apply(lambda col: col.str.title())\n",
    "duplicados = df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "cols_with_nulls = df.columns[df.isnull().any()]\n",
    "df[cols_with_nulls] = df[cols_with_nulls].astype('object')\n",
    "nulos_antes = df.isnull().sum().sum()\n",
    "df.fillna('Sin Datos', inplace=True)\n",
    "nulos_despues = df.isnull().sum().sum()\n",
    "valores_cambiados = nulos_antes - nulos_despues\n",
    "\n",
    "columns_to_impute = ['COLEGIO', 'COLEGIO_DEPA', 'COLEGIO_PROV', 'COLEGIO_DIST', 'COLEGIO_PAIS', 'ESPECIALIDAD',\n",
    "                         'DOMICILIO_DEPA', 'DOMICILIO_PROV', 'DOMICILIO_DIST', \n",
    "                         'NACIMIENTO_DEPA', 'NACIMIENTO_PROV',\n",
    "                         'NACIMIENTO_DIST', 'SEXO', 'INGRESO', 'MODALIDAD']\n",
    "\n",
    "for column in columns_to_impute:\n",
    "    df[column] = df[column].replace('Sin Datos', pd.NA)\n",
    "\n",
    "df = df.groupby('IDHASH').apply(lambda group: group.ffill())\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "nulos_despues2 = df.isnull().sum().sum()\n",
    "valores_cambiados2 = nulos_antes - nulos_despues2\n",
    "\n",
    "output_path = r'C:/Users/omarc/OneDrive/Escritorio/Proyectos VSC/OmarCano/Track Analítico UNI/05_Datos/02_Datos_Procesados/hm_admisiones_uni_limpio.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Resumen del Análisis Preliminar\")\n",
    "print(f\"Número de registros antes de limpieza: {len(df) + duplicados}\")\n",
    "print(f\"Número de registros después de limpieza: {len(df)}\")\n",
    "print(f\"Duplicados eliminados: {duplicados}\")\n",
    "print(f\"Valores nulos cambiados a 'Sin Datos': {valores_cambiados}\")\n",
    "print(f\"Valores nulos cambiados a 'Sin Datos' 2: {valores_cambiados2}\")\n",
    "print(\"\\nValores distintos por columna:\")\n",
    "for col, vals in distincts.items():\n",
    "    print(f\"{col}: {len(vals)} valores únicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza MATRICULADOS UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omarc\\AppData\\Local\\Temp\\ipykernel_25596\\3220159264.py:59: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('IDHASH').apply(lambda group: group.ffill())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del Análisis Preliminar\n",
      "Número de registros antes de limpieza: 192389\n",
      "Número de registros después de limpieza: 192389\n",
      "Duplicados eliminados: 0\n",
      "Valores nulos cambiados a 'Sin Datos': 58738\n",
      "Valores nulos cambiados a 'Sin Datos' 2: 251\n",
      "\n",
      "Valores distintos por columna:\n",
      "IDHASH: 26920 valores únicos\n",
      "COLEGIO_DEPA: 26 valores únicos\n",
      "COLEGIO_PROV: 177 valores únicos\n",
      "COLEGIO_DIST: 629 valores únicos\n",
      "ANIO: 9 valores únicos\n",
      "PERIODO: 2 valores únicos\n",
      "TIPO_MATRICULA: 9 valores únicos\n",
      "DOMICILIO_DEPA: 26 valores únicos\n",
      "DOMICILIO_PROV: 136 valores únicos\n",
      "DOMICILIO_DIST: 397 valores únicos\n",
      "ANIO_NACIMIENTO: 65 valores únicos\n",
      "NACIMIENTO_PAIS: 21 valores únicos\n",
      "NACIMIENTO_DEPA: 26 valores únicos\n",
      "NACIMIENTO_PROV: 185 valores únicos\n",
      "NACIMIENTO_DIST: 929 valores únicos\n",
      "SEXO: 2 valores únicos\n",
      "MODALIDAD: 28 valores únicos\n",
      "METODOLOGIA: 1 valores únicos\n",
      "FACULTAD: 11 valores únicos\n",
      "ESPECIALIDAD: 32 valores únicos\n",
      "CICLO_RELATIVO: 11 valores únicos\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:/Users/omarc/OneDrive/Escritorio/Proyectos VSC/OmarCano/Track Analítico UNI/05_Datos/01_Datos_Crudos/hm_matriculados_uni.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "distincts = {col: df[col].unique() for col in df.columns}\n",
    "df = df.apply(lambda col: col.str.strip() if col.dtype == 'object' else col)\n",
    "\n",
    "columns_to_capitalize = ['COLEGIO_DEPA', 'COLEGIO_PROV', 'COLEGIO_DIST',\n",
    "                         'TIPO_MATRICULA','DOMICILIO_DEPA', 'DOMICILIO_PROV', 'DOMICILIO_DIST', \n",
    "                         'NACIMIENTO_PAIS','NACIMIENTO_DEPA', 'NACIMIENTO_PROV','NACIMIENTO_DIST', \n",
    "                         'SEXO', 'MODALIDAD', 'METODOLOGIA','FACULTAD','ESPECIALIDAD']\n",
    "\n",
    "\n",
    "df[columns_to_capitalize] = df[columns_to_capitalize].apply(lambda col: col.str.title())\n",
    "duplicados = df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "cols_with_nulls = df.columns[df.isnull().any()]\n",
    "df[cols_with_nulls] = df[cols_with_nulls].astype('object')\n",
    "\n",
    "nulos_antes = df.isnull().sum().sum()\n",
    "df.fillna('Sin Datos', inplace=True)\n",
    "nulos_despues = df.isnull().sum().sum()\n",
    "valores_cambiados = nulos_antes - nulos_despues\n",
    "\n",
    "columns_to_impute = ['COLEGIO_DEPA', 'COLEGIO_PROV', 'COLEGIO_DIST',\n",
    "                         'TIPO_MATRICULA','DOMICILIO_DEPA', 'DOMICILIO_PROV', 'DOMICILIO_DIST', \n",
    "                         'NACIMIENTO_PAIS','NACIMIENTO_DEPA', 'NACIMIENTO_PROV','NACIMIENTO_DIST', \n",
    "                         'SEXO', 'MODALIDAD', 'METODOLOGIA','FACULTAD','ESPECIALIDAD']\n",
    "\n",
    "for column in columns_to_impute:\n",
    "    df[column] = df[column].replace('Sin Datos', pd.NA)\n",
    "    \n",
    "df = df.groupby('IDHASH').apply(lambda group: group.ffill())\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "nulos_despues2 = df.isnull().sum().sum()\n",
    "valores_cambiados2 = nulos_antes - nulos_despues2\n",
    "\n",
    "df['CODYEAR'] = df['ANIO'] * 10 + df['PERIODO']\n",
    "df['EDAD'] = df['ANIO'] - df['ANIO_NACIMIENTO']\n",
    "df['FLG_CAMBIO_CARRERA'] = df.groupby('IDHASH')['ESPECIALIDAD'].transform(lambda x: 1 if x.nunique() > 1 else 0)\n",
    "\n",
    "output_path = r'C:/Users/omarc/OneDrive/Escritorio/Proyectos VSC/OmarCano/Track Analítico UNI/05_Datos/02_Datos_Procesados/hm_matriculados_uni_limpio.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Resumen del Análisis Preliminar\")\n",
    "print(f\"Número de registros antes de limpieza: {len(df) + duplicados}\")\n",
    "print(f\"Número de registros después de limpieza: {len(df)}\")\n",
    "print(f\"Duplicados eliminados: {duplicados}\")\n",
    "print(f\"Valores nulos cambiados a 'Sin Datos': {valores_cambiados}\")\n",
    "print(f\"Valores nulos cambiados a 'Sin Datos' 2: {valores_cambiados2}\")\n",
    "print(\"\\nValores distintos por columna:\")\n",
    "for col, vals in distincts.items():\n",
    "    print(f\"{col}: {len(vals)} valores únicos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
